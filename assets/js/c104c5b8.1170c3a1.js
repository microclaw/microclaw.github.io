"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[4093],{1916(e,r,n){n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>c,default:()=>m,frontMatter:()=>d,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"memory","title":"Memory System","description":"MicroClaw has two complementary memory systems that are both injected into the system prompt on every request.","source":"@site/docs/memory.md","sourceDirName":".","slug":"/memory","permalink":"/docs/memory","draft":false,"unlisted":false,"editUrl":"https://github.com/microclaw/microclaw/tree/main/docs/memory.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"memory","title":"Memory System","sidebar_position":7},"sidebar":"docs","previous":{"title":"Tools Reference","permalink":"/docs/tools"},"next":{"title":"Scheduler","permalink":"/docs/scheduler"}}');var t=n(4848),i=n(8453);const d={id:"memory",title:"Memory System",sidebar_position:7},c=void 0,o={},l=[{value:"File memory (AGENTS.md)",id:"file-memory-agentsmd",level:2},{value:"Chat identity mapping",id:"chat-identity-mapping",level:2},{value:"Reflector (structured memories)",id:"reflector-structured-memories",level:2},{value:"Semantic memory behavior",id:"semantic-memory-behavior",level:2},{value:"Example",id:"example",level:2}];function a(e){const r={code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.p,{children:"MicroClaw has two complementary memory systems that are both injected into the system prompt on every request."}),"\n",(0,t.jsx)(r.h2,{id:"file-memory-agentsmd",children:"File memory (AGENTS.md)"}),"\n",(0,t.jsxs)(r.p,{children:["Manually written key-value style notes in ",(0,t.jsx)(r.code,{children:"AGENTS.md"})," files. The LLM writes these via the ",(0,t.jsx)(r.code,{children:"write_memory"})," tool."]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{children:"microclaw.data/runtime/groups/\n    AGENTS.md                 # Global memory (shared across all chats)\n    {chat_id}/\n        AGENTS.md             # Per-chat memory\n"})}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["LLM can read and write memory using ",(0,t.jsx)(r.code,{children:"read_memory"})," and ",(0,t.jsx)(r.code,{children:"write_memory"})]}),"\n",(0,t.jsxs)(r.li,{children:["Memory is wrapped in ",(0,t.jsx)(r.code,{children:"<global_memory>"})," and ",(0,t.jsx)(r.code,{children:"<chat_memory>"})," tags"]}),"\n",(0,t.jsxs)(r.li,{children:["The memory files live under ",(0,t.jsx)(r.code,{children:"DATA_DIR/runtime"})," (default ",(0,t.jsx)(r.code,{children:"./microclaw.data/runtime"}),")"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"write_memory"})," to ",(0,t.jsx)(r.code,{children:'scope: "global"'})," requires the caller chat to be in ",(0,t.jsx)(r.code,{children:"control_chat_ids"})]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"write_memory"})," also persists a structured memory row into SQLite (",(0,t.jsx)(r.code,{children:"memories"})," table)"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"chat-identity-mapping",children:"Chat identity mapping"}),"\n",(0,t.jsx)(r.p,{children:"SQLite stores chats with two identities:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"chat_id"}),": internal primary key used by sessions/messages/tasks"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"channel + external_chat_id"}),": source identity from Telegram/Discord/Web"]}),"\n"]}),"\n",(0,t.jsxs)(r.p,{children:["This prevents cross-channel collisions when numeric IDs overlap. Existing databases are migrated automatically at startup. Structured memories also store ",(0,t.jsx)(r.code,{children:"chat_channel"})," and ",(0,t.jsx)(r.code,{children:"external_chat_id"})," for easier debugging."]}),"\n",(0,t.jsx)(r.h2,{id:"reflector-structured-memories",children:"Reflector (structured memories)"}),"\n",(0,t.jsx)(r.p,{children:"A background process that automatically extracts and persists structured memories from conversations \u2014 independently of the main chat loop."}),"\n",(0,t.jsxs)(r.p,{children:["As sessions grow longer, the model tends to deprioritize voluntary ",(0,t.jsx)(r.code,{children:"write_memory"})," calls. The Reflector runs on a timer and extracts memories without relying on the model to remember to do so."]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"How it works:"})}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:["Every ",(0,t.jsx)(r.code,{children:"reflector_interval_mins"})," minutes (default 15), the Reflector scans recently-active chats"]}),"\n",(0,t.jsxs)(r.li,{children:["Per chat, it reads messages incrementally from a persisted cursor (",(0,t.jsx)(r.code,{children:"memory_reflector_state"}),") instead of rescanning full windows"]}),"\n",(0,t.jsxs)(r.li,{children:["It calls the LLM directly and extracts durable facts with strict category validation (",(0,t.jsx)(r.code,{children:"PROFILE"}),", ",(0,t.jsx)(r.code,{children:"KNOWLEDGE"}),", ",(0,t.jsx)(r.code,{children:"EVENT"}),")"]}),"\n",(0,t.jsxs)(r.li,{children:["Extracted memories are stored in SQLite (",(0,t.jsx)(r.code,{children:"memories"}),")"]}),"\n",(0,t.jsxs)(r.li,{children:["Dedup strategy:","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["with ",(0,t.jsx)(r.code,{children:"sqlite-vec"})," feature + runtime embedding configured: semantic nearest-neighbor check (cosine distance)"]}),"\n",(0,t.jsx)(r.li,{children:"otherwise: Jaccard overlap fallback"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Memory categories:"})}),"\n",(0,t.jsxs)(r.table,{children:[(0,t.jsx)(r.thead,{children:(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.th,{children:"Category"}),(0,t.jsx)(r.th,{children:"Description"})]})}),(0,t.jsxs)(r.tbody,{children:[(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.code,{children:"PROFILE"})}),(0,t.jsx)(r.td,{children:"User attributes and preferences"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.code,{children:"KNOWLEDGE"})}),(0,t.jsx)(r.td,{children:"Facts and areas of expertise"})]}),(0,t.jsxs)(r.tr,{children:[(0,t.jsx)(r.td,{children:(0,t.jsx)(r.code,{children:"EVENT"})}),(0,t.jsx)(r.td,{children:"Significant things that happened"})]})]})]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Injected in system prompt as:"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{children:"<structured_memories>\n[PROFILE] [chat] User is a Rust developer based in Tokyo\n[KNOWLEDGE] [chat] User prefers functional programming style\n</structured_memories>\n"})}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"Configuration:"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yaml",children:'reflector_enabled: true         # enable/disable background reflector\nreflector_interval_mins: 15     # how often to run (minutes)\nmemory_token_budget: 1500       # structured-memory injection budget\n\n# optional semantic memory runtime config (requires --features sqlite-vec build)\n# embedding_provider: "openai"  # openai | ollama\n# embedding_api_key: "..."\n# embedding_base_url: "..."\n# embedding_model: "text-embedding-3-small"\n# embedding_dim: 1536\n'})}),"\n",(0,t.jsxs)(r.p,{children:["Both can be changed via the setup wizard (",(0,t.jsx)(r.code,{children:"microclaw setup"}),") or the Web UI settings panel."]}),"\n",(0,t.jsxs)(r.p,{children:["When ",(0,t.jsx)(r.code,{children:"memory_token_budget"})," is exceeded during prompt construction, MicroClaw stops adding memories and appends ",(0,t.jsx)(r.code,{children:"(+N memories omitted)"}),"."]}),"\n",(0,t.jsx)(r.h2,{id:"semantic-memory-behavior",children:"Semantic memory behavior"}),"\n",(0,t.jsx)(r.p,{children:"Two-level safety model:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["Compile-time: ",(0,t.jsx)(r.code,{children:"sqlite-vec"})," feature is ",(0,t.jsx)(r.strong,{children:"off by default"})]}),"\n",(0,t.jsxs)(r.li,{children:["Runtime: ",(0,t.jsx)(r.code,{children:"embedding_provider"})," is ",(0,t.jsx)(r.strong,{children:"unset by default"})]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Runtime outcomes:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"sqlite-vec"})," enabled + embedding configured: semantic KNN retrieval and semantic dedup"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"sqlite-vec"})," enabled + embedding not configured: vector table may exist but retrieval/dedup still falls back"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"sqlite-vec"})," disabled: keyword retrieval + Jaccard dedup (stable baseline)"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"example",children:"Example"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{children:'You: Remember that I prefer Rust examples\nBot: Saved to chat memory.         # write_memory (file memory)\n\n[15 minutes later, automatically]\nReflector: extracted "User prefers Rust code examples" \u2192 memories table\n\n[Next session after /reset]\nBot: [has both AGENTS.md + structured memories in context]\n'})})]})}function m(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},8453(e,r,n){n.d(r,{R:()=>d,x:()=>c});var s=n(6540);const t={},i=s.createContext(t);function d(e){const r=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:d(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);